from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
import os
from dotenv import load_dotenv
import base64
import io
from PIL import Image
import re  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î

load_dotenv()

github_token = os.environ.get("GITHUB_TOKEN")
if not github_token:
    print("‚ö†Ô∏è WARNING: GITHUB_TOKEN is missing")

client = OpenAI(
    base_url="https://models.inference.ai.azure.com",
    api_key=github_token,
)

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

@app.get("/")
def read_root():
    return {"status": "GitHub Models (Llama 3.2 Vision) is Live! üêô"}

def process_image(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes))
        if img.mode in ('RGBA', 'P'):
            img = img.convert('RGB')
        
        # ‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏´‡∏ô‡πà‡∏≠‡∏¢ AI ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏á‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ß
        max_size = 800
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size))
            
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=70) 
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        
        return f"data:image/jpeg;base64,{img_str}"
    except Exception as e:
        print(f"Resize Error: {e}")
        return ""

# --- Endpoint Analyze ---
@app.post("/analyze")
async def analyze_ui(
    file: UploadFile = File(...), 
    country: str = Form(...), 
    context: str = Form(...)
):
    print(f"üì• Analyze Request: {country}")
    try:
        contents = await file.read()
        image_uri = process_image(contents)
        
        prompt = f"""
        Act as a UX/UI Expert. Analyze this UI for {country} culture.
        Context: {context}.
        Output ONLY raw HTML (no markdown code blocks) with this structure:
        <div class="score"> [Score 0-100] </div>
        <div class="issues"> [List of Critical Cultural Issues] </div>
        <div class="suggestions"> [List of Actionable Suggestions] </div>
        Keep it brief and direct.
        """
        
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "You are a helpful assistant that analyzes UI designs."},
                {"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": image_uri}}]}
            ],
            model="Llama-3.2-90B-Vision-Instruct",
            temperature=0.1,
            max_tokens=1000,
            top_p=1.0
        )
        
        result = response.choices[0].message.content
        # ‡∏•‡πâ‡∏≤‡∏á Markdown ‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏•‡∏µ‡πâ‡∏¢‡∏á
        clean_result = result.replace("```html", "").replace("```", "").strip()
        return {"result": clean_result}

    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {"result": f"<div style='color:red'><h3>System Error</h3><p>{str(e)}</p></div>"}

# --- Endpoint Fix (‡∏ï‡∏±‡∏ß‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ SVG Error) ---
@app.post("/fix")
async def fix_ui(
    file: UploadFile = File(...), 
    country: str = Form(...), 
    width: str = Form("375"),    
    height: str = Form("812")
):
    try:
        contents = await file.read()
        image_uri = process_image(contents)
        
        # ‡∏õ‡∏£‡∏±‡∏ö Prompt ‡πÉ‡∏´‡πâ‡∏î‡∏∏‡∏Ç‡∏∂‡πâ‡∏ô
        prompt = f"""
        Redesign this UI wireframe for {country} culture. Size: {width}x{height}.
        IMPORTANT: Output ONLY valid SVG code. 
        Start immediately with <svg ... and end with </svg>.
        Do not add any text, explanations, or markdown formatting.
        Use simple shapes (rect, circle, text). Ensure XML is valid.
        """
        
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "You are a UI generator that outputs strictly raw SVG code only."},
                {"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": image_uri}}]}
            ],
            model="Llama-3.2-90B-Vision-Instruct",
            temperature=0.1,
            max_tokens=2048,
            top_p=1.0
        )
        
        raw_content = response.choices[0].message.content
        print("ü§ñ Raw AI Response:", raw_content[:100]) # Log ‡∏î‡∏π‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏ß‡πà‡∏≤‡∏™‡πà‡∏á‡πÑ‡∏£‡∏°‡∏≤

        # ‚úÖ ‡πÉ‡∏ä‡πâ Regex ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ SVG ‡πÅ‡∏ö‡∏ö‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AI ‡∏û‡∏π‡∏î‡πÄ‡∏¢‡∏≠‡∏∞)
        match = re.search(r'<svg.*?</svg>', raw_content, re.DOTALL)
        
        if match:
            clean_svg = match.group(0)
            return {"svg": clean_svg}
        else:
            # üõ°Ô∏è ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤ SVG ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ Error ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ (‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏î‡πâ‡∏á)
            fallback_svg = f"""
            <svg width="{width}" height="{height}" xmlns="http://www.w3.org/2000/svg">
                <rect width="100%" height="100%" fill="#fee2e2"/>
                <text x="50%" y="50%" font-family="Arial" font-size="20" fill="#dc2626" text-anchor="middle" dominant-baseline="middle">
                    AI could not generate layout
                </text>
                <text x="50%" y="60%" font-family="Arial" font-size="14" fill="#dc2626" text-anchor="middle">
                    Try again or check logs
                </text>
            </svg>
            """
            print("‚ö†Ô∏è SVG Extraction failed, sending fallback.")
            return {"svg": fallback_svg}

    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {"svg": ""}